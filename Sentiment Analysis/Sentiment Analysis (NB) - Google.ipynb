{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1ca02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Modules\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO # For EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0937c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec-2022</td>\n",
       "      <td>@YaYaOregon Google gets a lot of work with som...</td>\n",
       "      <td>Canaansdad1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec-2022</td>\n",
       "      <td>SOCIALIZED MEDIA: HUNDREDS OF ISRAEL’S UNIT 82...</td>\n",
       "      <td>Tibou33969029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec-2022</td>\n",
       "      <td>@kennyraytheman @TimRunsHisMouth If you google...</td>\n",
       "      <td>kikjuicer9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec-2022</td>\n",
       "      <td>@jrozner at least she didn’t google it on her ...</td>\n",
       "      <td>oota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec-2022</td>\n",
       "      <td>@TAILZZZZZZ @stock_con_ @GeeScottSr @RNCResear...</td>\n",
       "      <td>ThotBoutit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Datetime                                               Text        Username\n",
       "0  Dec-2022  @YaYaOregon Google gets a lot of work with som...  Canaansdad1987\n",
       "1  Dec-2022  SOCIALIZED MEDIA: HUNDREDS OF ISRAEL’S UNIT 82...   Tibou33969029\n",
       "2  Dec-2022  @kennyraytheman @TimRunsHisMouth If you google...      kikjuicer9\n",
       "3  Dec-2022  @jrozner at least she didn’t google it on her ...            oota\n",
       "4  Dec-2022  @TAILZZZZZZ @stock_con_ @GeeScottSr @RNCResear...      ThotBoutit"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "Google_df = pd.read_csv('Dataset/Companies/google.csv')\n",
    "Google_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8cd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2992 entries, 0 to 2991\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Datetime  2992 non-null   object\n",
      " 1   Text      2992 non-null   object\n",
      " 2   Username  2992 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 70.2+ KB\n"
     ]
    }
   ],
   "source": [
    "Google_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e30394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2985 entries, 0 to 2991\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Datetime  2985 non-null   object\n",
      " 1   Text      2985 non-null   object\n",
      " 2   Username  2985 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 93.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Drop Duplicate Rows\n",
    "Google_df = Google_df.drop_duplicates()\n",
    "Google_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6519b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Data by Different Time Periods\n",
    "Google_Dec22 = Google_df[Google_df['Datetime'] == 'Dec-2022']\n",
    "Google_Jan23 = Google_df[Google_df['Datetime'] == 'Jan-2023']\n",
    "Google_Feb23 = Google_df[Google_df['Datetime'] == 'Feb-2023']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed5526",
   "metadata": {},
   "source": [
    "# Tweets PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692ac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove URLs\n",
    "Google_Dec22 = Google_Dec22['Text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "Google_Jan23 = Google_Jan23['Text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "Google_Feb23 = Google_Feb23['Text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef4b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove HTML Reference Characters\n",
    "Google_Dec22 = Google_Dec22.apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "Google_Jan23 = Google_Jan23.apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "Google_Feb23 = Google_Feb23.apply(lambda x: re.sub(r'&[a-z]+;', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188df064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Twitter Handles\n",
    "Google_Dec22 = Google_Dec22.apply(lambda x: re.sub(r'@[^ ]+', '', x))\n",
    "Google_Jan23 = Google_Jan23.apply(lambda x: re.sub(r'@[^ ]+', '', x))\n",
    "Google_Feb23 = Google_Feb23.apply(lambda x: re.sub(r'@[^ ]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb96b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Emojis with Words\n",
    "with open('Libraries/Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "Google_Dec22 = Google_Dec22.apply(convert_emojis_to_word)\n",
    "Google_Jan23 = Google_Jan23.apply(convert_emojis_to_word)\n",
    "Google_Feb23 = Google_Feb23.apply(convert_emojis_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f7b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace EMOTICONS with Words\n",
    "with open('Libraries/Emoticon_Dict.p', 'rb') as fp:\n",
    "    Emoticon_Dict = pickle.load(fp)\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    for emot in Emoticon_Dict:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(Emoticon_Dict[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "Google_Dec22 = Google_Dec22.apply(convert_emoticons)\n",
    "Google_Jan23 = Google_Jan23.apply(convert_emoticons)\n",
    "Google_Feb23 = Google_Feb23.apply(convert_emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771c147",
   "metadata": {},
   "source": [
    "# Perform Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae6a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training Dataset\n",
    "training_dataset = pd.read_csv('Dataset/Training/training_dataset.csv', encoding='latin-1')\n",
    "\n",
    "#Create Training Data\n",
    "train_text = []\n",
    "for index,row in training_dataset.iterrows():\n",
    "    train_text.append((row['Text'], row['Label']))\n",
    "\n",
    "#Feature Extraction Function\n",
    "def extract_features(text):\n",
    "    words = word_tokenize(text)\n",
    "    return dict((word, True) for word in words)\n",
    "\n",
    "#Create Feature Sets from Training Data\n",
    "train_features = [(extract_features(text), label) for (text, label) in train_text]\n",
    "\n",
    "#Train the Classifier\n",
    "classifier = NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "#For Google December 2022\n",
    "test_df1 = Google_Dec22.to_frame()\n",
    "for index,row in test_df1.iterrows():\n",
    "    test_features = extract_features(row['Text'])\n",
    "    predicted_label = classifier.classify(test_features)\n",
    "    test_df1.at[index,'sentiment'] = predicted_label\n",
    "    \n",
    "#For Google January 2023\n",
    "test_df2 = Google_Jan23.to_frame()\n",
    "for index,row in test_df2.iterrows():\n",
    "    test_features = extract_features(row['Text'])\n",
    "    predicted_label = classifier.classify(test_features)\n",
    "    test_df2.at[index,'sentiment'] = predicted_label\n",
    "    \n",
    "#For Google Februrary 2023\n",
    "test_df3 = Google_Feb23.to_frame()\n",
    "for index,row in test_df3.iterrows():\n",
    "    test_features = extract_features(row['Text'])\n",
    "    predicted_label = classifier.classify(test_features)\n",
    "    test_df3.at[index,'sentiment'] = predicted_label\n",
    "\n",
    "#Export Sentiments Predicted Dataset\n",
    "test_df1.to_csv(\"Dataset/Sentiments Predicted/GoogleDec22_Sentiments.csv\")\n",
    "test_df2.to_csv(\"Dataset/Sentiments Predicted/GoogleJan23_Sentiments.csv\")\n",
    "test_df3.to_csv(\"Dataset/Sentiments Predicted/GoogleFeb23_Sentiments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8c012",
   "metadata": {},
   "source": [
    "# Analysis of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a249f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google December 2022\n",
      "Positive Labels: 0.17386934673366833\n",
      "Negative Labels: 0.7819095477386935\n",
      "Neutral Labels: 0.044221105527638194\n",
      "--------------------\n",
      "Google January 2023\n",
      "Positive Labels: 0.16933867735470942\n",
      "Negative Labels: 0.7905811623246493\n",
      "Neutral Labels: 0.04008016032064128\n",
      "--------------------\n",
      "Google February 2023\n",
      "Positive Labels: 0.1774193548387097\n",
      "Negative Labels: 0.78125\n",
      "Neutral Labels: 0.04133064516129032\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "Google_Dec22 = pd.read_csv(\"Dataset/Sentiments Predicted/GoogleDec22_Sentiments.csv\", encoding='latin-1')\n",
    "Google_Jan23 = pd.read_csv(\"Dataset/Sentiments Predicted/GoogleJan23_Sentiments.csv\", encoding='latin-1')\n",
    "Google_Feb23 = pd.read_csv(\"Dataset/Sentiments Predicted/GoogleFeb23_Sentiments.csv\", encoding='latin-1')\n",
    "\n",
    "#Used to Store the Labels & Total Number of Tweets\n",
    "labels_Google_Dec22 = []\n",
    "count_Google_Dec22 = 0\n",
    "labels_Google_Jan23 = []\n",
    "count_Google_Jan23 = 0\n",
    "labels_Google_Feb23 = []\n",
    "count_Google_Feb23 = 0\n",
    "\n",
    "#For Google December 2022\n",
    "for index,row in Google_Dec22.iterrows():\n",
    "    labels_Google_Dec22.append(row['sentiment'])\n",
    "    count_Google_Dec22 += 1\n",
    "\n",
    "#Count the Number of Positive, Negative and Neutral Labels\n",
    "num_positives = labels_Google_Dec22.count('pos')\n",
    "num_negatives = labels_Google_Dec22.count('neg')\n",
    "num_neutral = labels_Google_Dec22.count('neu')\n",
    "\n",
    "#Print the Results\n",
    "print('Google December 2022')\n",
    "print('Positive Labels:', num_positives/count_Google_Dec22)\n",
    "print('Negative Labels:', num_negatives/count_Google_Dec22)\n",
    "print('Neutral Labels:', num_neutral/count_Google_Dec22)\n",
    "\n",
    "\n",
    "#For Google January 2023\n",
    "for index,row in Google_Jan23.iterrows():\n",
    "    labels_Google_Jan23.append(row['sentiment'])\n",
    "    count_Google_Jan23 += 1\n",
    "\n",
    "#Count the Number of Positive, Negative and Neutral Labels\n",
    "num_positives = labels_Google_Jan23.count('pos')\n",
    "num_negatives = labels_Google_Jan23.count('neg')\n",
    "num_neutral = labels_Google_Jan23.count('neu')\n",
    "\n",
    "#Print the Results\n",
    "print('--------------------')\n",
    "print('Google January 2023')\n",
    "print('Positive Labels:', num_positives/count_Google_Jan23)\n",
    "print('Negative Labels:', num_negatives/count_Google_Jan23)\n",
    "print('Neutral Labels:', num_neutral/count_Google_Jan23)\n",
    "\n",
    "#For Google February 2023\n",
    "for index,row in Google_Feb23.iterrows():\n",
    "    labels_Google_Feb23.append(row['sentiment'])\n",
    "    count_Google_Feb23 += 1\n",
    "\n",
    "#Count the Number of Positive, Negative and Neutral Labels\n",
    "num_positives = labels_Google_Feb23.count('pos')\n",
    "num_negatives = labels_Google_Feb23.count('neg')\n",
    "num_neutral = labels_Google_Feb23.count('neu')\n",
    "\n",
    "#Print the Results\n",
    "print('--------------------')\n",
    "print('Google February 2023')\n",
    "print('Positive Labels:', num_positives/count_Google_Feb23)\n",
    "print('Negative Labels:', num_negatives/count_Google_Feb23)\n",
    "print('Neutral Labels:', num_neutral/count_Google_Feb23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
